# -*- coding: utf-8 -*-
"""get_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13o9xrjdLFA6CDYYI_tMNz7FDlnP-f4AC
"""

import requests
from bs4 import BeautifulSoup
import csv

def scrape_wikipedia_page(url, file_name):
    response = requests.get(url)
    if response.status_code != 200:
        print(f"请求失败，状态码：{response.status_code}")
        return

    soup = BeautifulSoup(response.content, 'html.parser')

    # 找到所有标题和段落
    elements = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p'])

    with open(file_name, 'w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(['Type', 'Content'])

        for element in elements:
            element_type = element.name
            element_content = element.get_text().strip()
            writer.writerow([element_type, element_content])

    print(f"内容已保存到 {file_name}")

# 爬取英文版本的页面
scrape_wikipedia_page(
    "https://en.wikipedia.org/wiki/Israeli%E2%80%93Palestinian_conflict",
    "Wikipedia_English_version_of_the_Palestinian-Israeli_conflict_yifan.csv"
)

# 爬取中文版本的页面
scrape_wikipedia_page(
    "https://zh.wikipedia.org/wiki/%E4%BB%A5%E5%B7%B4%E5%86%B2%E7%AA%81",
    "Wikipedia_Chinese_version_of_the_Palestinian-Israeli_conflict_yifan.csv"
)