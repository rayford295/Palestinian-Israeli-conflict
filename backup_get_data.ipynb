{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "\n",
        "# Define a function to scrape Wikipedia pages\n",
        "def yifan_scrape_wikipedia_page(url, file_name):\n",
        "    response = requests.get(url)\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Request failed, status code: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Find all headers and paragraphs\n",
        "    elements = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p'])\n",
        "\n",
        "    with open(file_name, 'w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Type', 'Content'])\n",
        "\n",
        "        # Write the type and content of each element to the CSV\n",
        "        for element in elements:\n",
        "            element_type = element.name\n",
        "            element_content = element.get_text().strip()\n",
        "            writer.writerow([element_type, element_content])\n",
        "\n",
        "    print(f\"Wikipedia data has been saved to {file_name}\")\n",
        "\n",
        "# Define a function to save news from Google News RSS feed to a CSV file\n",
        "def yifan_save_news_to_csv(rss_url, csv_filename):\n",
        "    response = requests.get(rss_url)\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Request failed, status code: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    root = ET.fromstring(response.content)\n",
        "    news_items = []\n",
        "\n",
        "    # Parse the RSS feed and extract news items\n",
        "    for item in root.findall('./channel/item'):\n",
        "        news_dict = {\n",
        "            'title': item.find('title').text,\n",
        "            'link': item.find('link').text,\n",
        "            'pubDate': item.find('pubDate').text\n",
        "        }\n",
        "        news_items.append(news_dict)\n",
        "\n",
        "    with open(csv_filename, 'w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=['title', 'link', 'pubDate'])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(news_items)\n",
        "\n",
        "    print(f\"Google News data has been saved to {csv_filename}\")\n",
        "\n",
        "# Scrape English Wikipedia page\n",
        "yifan_scrape_wikipedia_page(\n",
        "    \"https://en.wikipedia.org/wiki/Israeli%E2%80%93Palestinian_conflict\",\n",
        "    \"Wikipedia_English_version_of_the_Palestinian-Israeli_conflict_yifan.csv\"\n",
        ")\n",
        "\n",
        "# Scrape Chinese Wikipedia page\n",
        "yifan_scrape_wikipedia_page(\n",
        "    \"https://zh.wikipedia.org/zh-cn/%E4%BB%A5%E5%B7%B4%E5%86%B2%E7%AA%81\",\n",
        "    \"Wikipedia_Chinese_version_of_the_Palestinian-Israeli_conflict_yifan.csv\"\n",
        ")\n",
        "\n",
        "# Save English Google News RSS feed\n",
        "yifan_save_news_to_csv(\n",
        "    'https://news.google.com/rss/search?q=Israeli-Palestinian+conflict&hl=en-US&gl=US&ceid=US:en',\n",
        "    'English_version_of_Google_News_crawling_yifan.csv'\n",
        ")\n",
        "\n",
        "# Save Chinese Google News RSS feed\n",
        "yifan_save_news_to_csv(\n",
        "    'https://news.google.com/rss/search?q=%E5%B7%B4%E4%BB%A5%E5%86%B2%E7%AA%81&hl=zh-CN&gl=CN&ceid=CN:zh-Hans',\n",
        "    'Chinese_version_of_Google_News_crawling_yifan.csv'\n",
        ")\n"
      ],
      "metadata": {
        "id": "rKbIbaiJvUFC",
        "outputId": "e346c682-d899-46d8-a943-e9628d08a31a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wikipedia data has been saved to Wikipedia_English_version_of_the_Palestinian-Israeli_conflict_yifan.csv\n",
            "Wikipedia data has been saved to Wikipedia_Chinese_version_of_the_Palestinian-Israeli_conflict_yifan.csv\n",
            "Google News data has been saved to English_version_of_Google_News_crawling_yifan.csv\n",
            "Google News data has been saved to Chinese_version_of_Google_News_crawling_yifan.csv\n"
          ]
        }
      ]
    }
  ]
}